{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f11c630-3773-4976-9ebd-800168ce378f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Memory-Based Collaborative Filtering model trained.\n",
      "üìä Collaborative Filtering Evaluation Metrics:\n",
      "Precision: 0.9759\n",
      "Recall: 0.7358\n",
      "Accuracy: 0.9898\n",
      "F1 Score: 0.8390\n",
      "\n",
      "‚úÖ Collaborative Filtering model saved successfully.\n",
      "üìå Sample User: nishanthvasudeva\n",
      "\n",
      "Top Similar Users:\n",
      "        Target User Similar User  Cosine Similarity\n",
      "0  nishanthvasudeva      sharvin                1.0\n",
      "1  nishanthvasudeva  suhaibsiraj                1.0\n",
      "2  nishanthvasudeva   janhavi172                1.0\n",
      "\n",
      "Top University Recommendations:\n",
      "          Recommended University  Predicted Score\n",
      "0  university of texas arlington         0.492752\n",
      "1         wayne state university         0.109585\n",
      "2     university of texas dallas         0.089681\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "# 1. LOAD THE DATASET\n",
    "\n",
    "df = pd.read_csv('./data/categorized_specializations.csv')\n",
    "\n",
    "# Handle skew by removing low-count university names\n",
    "min_samples_per_class = 50\n",
    "valid_classes = df['univName'].value_counts()\n",
    "valid_classes = valid_classes[valid_classes >= min_samples_per_class].index\n",
    "df = df[df['univName'].isin(valid_classes)]\n",
    "# One-hot encoding univ_state \n",
    "df = pd.get_dummies(df, columns=['univ_state'], drop_first=True)\n",
    "\n",
    "# Label encoding categorical columns\n",
    "def encode_categorical_columns(df, categorical_columns):\n",
    "    label_encoders = {}\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = df[col].astype(str)\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "        label_encoders[col] = le\n",
    "    return df, label_encoders\n",
    "\n",
    "# Scaling continuous columns\n",
    "def scale_numerical_columns(df, numerical_columns):\n",
    "    scaler = StandardScaler()\n",
    "    df[numerical_columns] = df[numerical_columns].replace([np.inf, -np.inf], np.nan)\n",
    "    df[numerical_columns] = df[numerical_columns].fillna(df[numerical_columns].mean())\n",
    "    df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "    return df, scaler\n",
    "\n",
    "\n",
    "# 2. MEMORY-BASED COLLABORATIVE FILTERING CLASS\n",
    "\n",
    "from memory_cf import MemoryBasedCF\n",
    "\n",
    "\n",
    "# 3. TRAINING THE CF MODEL\n",
    "\n",
    "def train_collaborative_filtering_memory(df, user_col, item_col, rating_col):\n",
    "    \"\"\"\n",
    "    Trains a memory-based collaborative filtering model:\n",
    "      - Creates a pivot table for users and items.\n",
    "      - Normalizes ratings to be between 0 and 1.\n",
    "      - Computes cosine similarity.\n",
    "    Returns an instance of MemoryBasedCF.\n",
    "    \"\"\"\n",
    "    df[user_col] = df[user_col].astype(str)\n",
    "    df[item_col] = df[item_col].astype(str)\n",
    "    \n",
    "    # Normalize the rating column to a [0, 1] scale.\n",
    "    df[rating_col] = (df[rating_col] - df[rating_col].min()) / (df[rating_col].max() - df[rating_col].min())\n",
    "    \n",
    "    df_pivot = df.pivot_table(index=user_col, columns=item_col, values=rating_col, aggfunc='mean', fill_value=0)\n",
    "    cf_model = MemoryBasedCF(df_pivot)\n",
    "    print(\"‚úÖ Memory-Based Collaborative Filtering model trained.\")\n",
    "    return cf_model, df_pivot\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def evaluate_cf_model_precision_recall_accuracy_f1(cf_model, df_pivot, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Evaluates the collaborative filtering model using Precision, Recall, Accuracy, and F1-score based on \n",
    "    predicted and actual ratings, considering ratings above a threshold as relevant.\n",
    "    \"\"\"\n",
    "    actual_relevance = []\n",
    "    predicted_relevance = []\n",
    "    \n",
    "    for user in df_pivot.index:\n",
    "        actual = df_pivot.loc[user].values\n",
    "        predicted = cf_model.predict(user)\n",
    "        \n",
    "        # Convert ratings to relevance (1 if relevant, 0 if not)\n",
    "        actual_relevance.extend((actual >= threshold).astype(int))\n",
    "        predicted_relevance.extend((predicted >= threshold).astype(int))\n",
    "    \n",
    "    # Compute Precision, Recall, Accuracy, and F1-Score\n",
    "    precision = precision_score(actual_relevance, predicted_relevance)\n",
    "    recall = recall_score(actual_relevance, predicted_relevance)\n",
    "    accuracy = accuracy_score(actual_relevance, predicted_relevance)\n",
    "    f1 = f1_score(actual_relevance, predicted_relevance)\n",
    "\n",
    "    print(f\"üìä Collaborative Filtering Evaluation Metrics:\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    return precision, recall, accuracy, f1\n",
    "\n",
    "\n",
    "\n",
    "# 5. RUN TRAINING & EVALUATION WITH PRECISION/RECALL\n",
    "\n",
    "# Train the collaborative filtering model\n",
    "cf_model, df_pivot = train_collaborative_filtering_memory(df, 'userName', 'univName', 'admit')\n",
    "\n",
    "# Evaluate the CF model using Precision, Recall, Accuracy, and F1-Score\n",
    "precision, recall, accuracy, f1 = evaluate_cf_model_precision_recall_accuracy_f1(cf_model, df_pivot)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(cf_model, \"models/university_models/cf_model_memory.pkl\")\n",
    "\n",
    "print(\"\\n‚úÖ Collaborative Filtering model saved successfully.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_top_similar_users(user_id, similarity_matrix, top_n=3):\n",
    "    similar_scores = similarity_matrix.loc[user_id].drop(user_id)  \n",
    "    top_similar = similar_scores.sort_values(ascending=False).head(top_n)\n",
    "    return top_similar\n",
    "\n",
    "def get_top_recommendations(user_id, cf_model, top_n=3):\n",
    "    predictions = cf_model.predict(user_id)\n",
    "    sorted_indices = np.argsort(predictions)[::-1]  \n",
    "    university_names = df_pivot.columns[sorted_indices][:top_n]\n",
    "    scores = predictions[sorted_indices][:top_n]\n",
    "    return list(zip(university_names, scores))\n",
    "\n",
    "def format_similar_users_table(user_id, similarity_matrix, top_n=3):\n",
    "    top_similar = get_top_similar_users(user_id, similarity_matrix, top_n)\n",
    "    return pd.DataFrame({\n",
    "        'Target User': user_id,\n",
    "        'Similar User': top_similar.index,\n",
    "        'Cosine Similarity': top_similar.values\n",
    "    })\n",
    "\n",
    "def format_top_recommendations_table(user_id, cf_model, top_n=3):\n",
    "    top_recs = get_top_recommendations(user_id, cf_model, top_n)\n",
    "    return pd.DataFrame(top_recs, columns=['Recommended University', 'Predicted Score'])\n",
    "\n",
    "\n",
    "user_id = 'nishanthvasudeva'\n",
    "similarity_matrix = pd.DataFrame(\n",
    "    cosine_similarity(df_pivot),\n",
    "    index=df_pivot.index,\n",
    "    columns=df_pivot.index\n",
    ")\n",
    "\n",
    "if user_id in df_pivot.index:\n",
    "    similar_users_df = format_similar_users_table(user_id, similarity_matrix)\n",
    "    recommendations_df = format_top_recommendations_table(user_id, cf_model)\n",
    "\n",
    "    print(f\"üìå Sample User: {user_id}\\n\")\n",
    "    print(\"Top Similar Users:\")\n",
    "    print(similar_users_df)\n",
    "\n",
    "    print(\"\\nTop University Recommendations:\")\n",
    "    print(recommendations_df)\n",
    "else:\n",
    "    print(f\"‚ùå User ID '{user_id}' not found in dataset.\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5e5e512-9fa9-42e8-9993-2916c9c4ce8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Sample User: User_4317\n",
      "\n",
      "Top Similar Users:\n",
      "Target User Similar User  Cosine Similarity\n",
      "  User_4317    User_5489           0.866025\n",
      "  User_4317    User_8276           0.816497\n",
      "  User_4317   User_10568           0.816497\n",
      "\n",
      "Top University Recommendations:\n",
      "           Recommended University  Predicted Score\n",
      "university of southern california         0.247129\n",
      "               clemson university         0.087625\n",
      "         arizona state university         0.064133\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_top_similar_users(user_id, similarity_matrix, top_n=3):\n",
    "    similar_scores = similarity_matrix.loc[user_id].drop(user_id)  \n",
    "    top_similar = similar_scores.sort_values(ascending=False).head(top_n)\n",
    "    return top_similar\n",
    "\n",
    "def get_top_recommendations(user_id, cf_model, top_n=3):\n",
    "    predictions = cf_model.predict(user_id)\n",
    "    sorted_indices = np.argsort(predictions)[::-1]  \n",
    "    university_names = df_pivot.columns[sorted_indices][:top_n]\n",
    "    scores = predictions[sorted_indices][:top_n]\n",
    "    return list(zip(university_names, scores))\n",
    "\n",
    "def format_similar_users_table(user_id, similarity_matrix, user_id_map, top_n=3):\n",
    "    top_similar = get_top_similar_users(user_id, similarity_matrix, top_n)\n",
    "    return pd.DataFrame({\n",
    "        'Target User': user_id_map[user_id],\n",
    "        'Similar User': [user_id_map[u] for u in top_similar.index],\n",
    "        'Cosine Similarity': top_similar.values\n",
    "    })\n",
    "\n",
    "def format_top_recommendations_table(user_id, cf_model, top_n=3):\n",
    "    top_recs = get_top_recommendations(user_id, cf_model, top_n)\n",
    "    return pd.DataFrame(top_recs, columns=['Recommended University', 'Predicted Score'])\n",
    "\n",
    "\n",
    "# Sample user for university recommendation\n",
    "user_id = 'gvr'\n",
    "\n",
    "# Create anonymized ID mapping for users in df_pivot\n",
    "user_id_map = {user: f\"User_{i}\" for i, user in enumerate(df_pivot.index)}\n",
    "\n",
    "# Compute similarity matrix for university CF\n",
    "similarity_matrix = pd.DataFrame(\n",
    "    cosine_similarity(df_pivot),\n",
    "    index=df_pivot.index,\n",
    "    columns=df_pivot.index\n",
    ")\n",
    "\n",
    "if user_id in df_pivot.index:\n",
    "    similar_users_df = format_similar_users_table(user_id, similarity_matrix, user_id_map)\n",
    "    recommendations_df = format_top_recommendations_table(user_id, cf_model)\n",
    "\n",
    "    print(f\"üìå Sample User: {user_id_map[user_id]}\\n\")\n",
    "    print(\"Top Similar Users:\")\n",
    "    print(similar_users_df.to_string(index=False))\n",
    "\n",
    "    print(\"\\nTop University Recommendations:\")\n",
    "    print(recommendations_df.to_string(index=False))\n",
    "else:\n",
    "    print(f\"‚ùå User ID '{user_id}' not found in dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f012b7dd-2880-4341-b3e0-6418a95ce948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All models and preprocessing objects loaded successfully.\n",
      "\n",
      "üìä Hybrid Model Evaluation Results:\n",
      "Hybrid Model Accuracy: 0.8558\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      3727\n",
      "           1       0.54      0.69      0.60        54\n",
      "           2       0.87      0.86      0.87      1600\n",
      "           3       1.00      1.00      1.00       933\n",
      "           4       0.57      0.67      0.62       518\n",
      "           5       0.65      0.69      0.67       685\n",
      "           6       0.89      0.93      0.91       461\n",
      "           7       1.00      1.00      1.00      2368\n",
      "           8       0.85      0.84      0.85       228\n",
      "           9       0.79      0.82      0.80       100\n",
      "          10       0.93      0.96      0.94       545\n",
      "          11       0.59      0.62      0.61       502\n",
      "          12       0.94      0.95      0.94      4149\n",
      "          13       0.93      0.93      0.93      2242\n",
      "          14       0.79      0.79      0.79       112\n",
      "          15       0.91      0.92      0.92      1114\n",
      "          16       0.98      0.83      0.90        59\n",
      "          17       1.00      1.00      1.00      1270\n",
      "          18       0.95      0.93      0.94       619\n",
      "          19       0.53      0.67      0.59       422\n",
      "          20       0.76      0.71      0.73      2636\n",
      "          21       0.69      0.68      0.68      1852\n",
      "          22       0.69      0.71      0.70      1445\n",
      "          23       0.78      0.73      0.75      2455\n",
      "          24       0.89      0.80      0.84      1041\n",
      "          25       0.64      0.92      0.75       284\n",
      "          26       0.67      0.59      0.63      1187\n",
      "          27       0.51      0.55      0.53       652\n",
      "          28       0.56      0.55      0.55       809\n",
      "          29       0.54      0.56      0.55       608\n",
      "          30       0.54      0.73      0.62       176\n",
      "          31       0.93      0.92      0.92      1236\n",
      "          32       1.00      1.00      1.00       912\n",
      "          33       1.00      1.00      1.00      2743\n",
      "          34       0.95      0.94      0.94      2064\n",
      "          35       0.87      0.88      0.88       940\n",
      "          36       0.97      0.97      0.97      1245\n",
      "          37       0.87      0.86      0.87      1037\n",
      "          38       0.99      0.98      0.98       793\n",
      "          39       1.00      1.00      1.00      1540\n",
      "          40       0.77      0.68      0.72       116\n",
      "          41       0.83      0.81      0.82      1237\n",
      "          42       0.79      0.80      0.79      1009\n",
      "          43       0.78      0.71      0.74      2253\n",
      "          44       0.72      0.69      0.71      1251\n",
      "          45       0.70      0.76      0.73      1293\n",
      "          46       0.81      0.82      0.81      3761\n",
      "          47       1.00      1.00      1.00       724\n",
      "          48       1.00      1.00      1.00       514\n",
      "          49       1.00      1.00      1.00      1097\n",
      "          50       0.97      0.96      0.97      1191\n",
      "          51       0.92      0.94      0.93       189\n",
      "          52       0.73      0.81      0.77       159\n",
      "\n",
      "    accuracy                           0.86     62157\n",
      "   macro avg       0.82      0.83      0.83     62157\n",
      "weighted avg       0.86      0.86      0.86     62157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# 1. LOAD SAVED MODELS & PREPROCESSING OBJECTS\n",
    "\n",
    "save_dir = \"models/university_models\"\n",
    "\n",
    "# Load the trained Random Forest model \n",
    "models_univ = joblib.load(os.path.join(save_dir, 'rf_university.pkl'))\n",
    "rf_model = models_univ['Random Forest'][0]  \n",
    "\n",
    "# Load collaborative filtering model (memory-based CF)\n",
    "cf_model = joblib.load(os.path.join(save_dir, 'cf_model_memory.pkl'))\n",
    "\n",
    "# Load preprocessing objects\n",
    "scaler_univ = joblib.load(os.path.join(save_dir, 'scaler_university.pkl'))\n",
    "label_encoders_univ = joblib.load(os.path.join(save_dir, 'label_encoders_university.pkl'))\n",
    "le_y_univ = joblib.load(os.path.join(save_dir, 'le_y_univ.pkl'))\n",
    "one_hot_columns = joblib.load(os.path.join(save_dir, \"one_hot_columns_university.pkl\"))\n",
    "\n",
    "print(\"‚úÖ All models and preprocessing objects loaded successfully.\")\n",
    "\n",
    "# Define the feature set used during training:\n",
    "univ_categorical = ['ugCollege', 'specialization_category']\n",
    "univ_numerical   = ['toeflScore', 'greV', 'greQ', 'greA', 'normalized_cgpa']\n",
    "\n",
    "\n",
    "# 2. HYBRID RECOMMENDER FUNCTION\n",
    "\n",
    "import numpy as np\n",
    "def hybrid_university_recommendation(input_df, content_model, collab_model, label_encoder, \n",
    "                                     is_university=False, state=None, one_hot_columns=None):\n",
    "    \"\"\"\n",
    "    Generates university recommendations by combining:\n",
    "      - Content-based predictions (using the Random Forest classifier).\n",
    "      - Collaborative filtering predictions (using memory-based CF).\n",
    "    Includes an optional state filter for university recommendations.\n",
    "    Returns the top 3 recommended universities (decoded).\n",
    "    \"\"\"\n",
    "    input_features = input_df.drop(columns=['userName'], errors='ignore')\n",
    "    \n",
    "    # --- Content-based predictions ---\n",
    "    if is_university:\n",
    "        if state is None and one_hot_columns is not None:\n",
    "\n",
    "            probs_list = []\n",
    "            for state_col in one_hot_columns:\n",
    "                temp_df = input_features.copy()\n",
    "                temp_df[one_hot_columns] = 0  \n",
    "                temp_df[state_col] = 1  \n",
    "                try:\n",
    "                    probs = content_model.predict_proba(temp_df)[0]\n",
    "                except Exception:\n",
    "                    probs = content_model.predict(temp_df)\n",
    "                probs_list.append(probs)\n",
    "            content_probs = np.mean(probs_list, axis=0)\n",
    "        else:\n",
    "            # Use the input_df directly if a specific state is selected\n",
    "            try:\n",
    "                content_probs = content_model.predict_proba(input_features)[0]\n",
    "            except Exception:\n",
    "                content_probs = content_model.predict(input_features)\n",
    "    else:\n",
    "        # Default content-based prediction\n",
    "        try:\n",
    "            content_probs = content_model.predict_proba(input_features)[0]\n",
    "        except Exception:\n",
    "            content_probs = content_model.predict(input_features)\n",
    "    \n",
    "    # --- Collaborative filtering predictions ---\n",
    "    if 'userName' in input_df.columns:\n",
    "        input_user = input_df.iloc[0]['userName']\n",
    "        collab_probs = collab_model.predict(input_user)\n",
    "    else:\n",
    "        collab_probs = np.zeros_like(content_probs)\n",
    "    \n",
    "    # --- Combine predictions using variance-based weighting ---\n",
    "    alpha = np.var(content_probs) / (np.var(content_probs) + np.var(collab_probs) + 1e-5)\n",
    "    final_probs = (content_probs * alpha) + (collab_probs * (1 - alpha))\n",
    "    \n",
    "    # Select top 3 recommendations\n",
    "    top_n = 3\n",
    "    top_indices = np.argsort(final_probs)[-top_n:][::-1]\n",
    "    recommendations = label_encoder.inverse_transform(top_indices)\n",
    "    # If a specific state was requested, filter the recommendations accordingly.\n",
    "    if state is not None:\n",
    "        filtered_recommendations = [rec for rec in final_recommendations \n",
    "                                    if rec in df[df['univ_state'] == state]['univName'].values]\n",
    "        if len(filtered_recommendations) < top_n:\n",
    "            st.warning(f\"‚ö†Ô∏è Only {len(filtered_recommendations)} universities found in {state}. Expanding recommendations.\")\n",
    "            filtered_recommendations = final_recommendations\n",
    "        return filtered_recommendations\n",
    "            \n",
    "    return recommendations\n",
    "\n",
    "\n",
    "# 3. EVALUATION FUNCTION FOR THE HYBRID MODEL\n",
    "\n",
    "def evaluate_hybrid_model(X_test, y_test, rf_model, cf_model, le_y, one_hot_columns):\n",
    "    \"\"\"\n",
    "    Evaluates the hybrid recommender system by:\n",
    "      - For each test sample, obtaining hybrid recommendations.\n",
    "      - Taking the top recommendation as the predicted label.\n",
    "      - Comparing against the true label.\n",
    "    Prints accuracy and a classification report.\n",
    "    \"\"\"\n",
    "    y_test_encoded = le_y.transform(y_test)\n",
    "    y_pred = []\n",
    "    \n",
    "    for i in range(len(X_test)):\n",
    "        sample = X_test.iloc[[i]].copy()\n",
    "        if 'userName' not in sample.columns:\n",
    "            sample['userName'] = \"dummy_user\"\n",
    "        \n",
    "        recs = hybrid_university_recommendation(sample, rf_model, cf_model, le_y, one_hot_columns)\n",
    "        # Use the top recommendation as the prediction\n",
    "        if len(recs) > 0:\n",
    "            pred = le_y.transform([recs[0]])[0]\n",
    "        else:\n",
    "            pred = -1\n",
    "        y_pred.append(pred)\n",
    "    \n",
    "    # Remove invalid predictions if any\n",
    "    valid_idx = [i for i, p in enumerate(y_pred) if p != -1]\n",
    "    y_true_valid = np.array([y_test_encoded[i] for i in valid_idx])\n",
    "    y_pred_valid = np.array([y_pred[i] for i in valid_idx])\n",
    "    \n",
    "    acc = accuracy_score(y_true_valid, y_pred_valid)\n",
    "    print(\"\\nüìä Hybrid Model Evaluation Results:\")\n",
    "    print(f\"Hybrid Model Accuracy: {acc:.4f}\")\n",
    "    print(classification_report(y_true_valid, y_pred_valid))\n",
    "\n",
    "\n",
    "# 4. PREPROCESS TEST DATA\n",
    "\n",
    "df_test = pd.read_csv('./data/categorized_specializations.csv')\n",
    "\n",
    "min_samples_per_class = 50\n",
    "valid_classes = df_test['univName'].value_counts()\n",
    "valid_classes = valid_classes[valid_classes >= min_samples_per_class].index\n",
    "df_test = df_test[df_test['univName'].isin(valid_classes)]\n",
    "\n",
    "\n",
    "def encode_categorical_columns(df, categorical_columns):\n",
    "    label_encoders = {}\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = df[col].astype(str)\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "        label_encoders[col] = le\n",
    "    return df, label_encoders\n",
    "\n",
    "def scale_numerical_columns(df, numerical_columns):\n",
    "    scaler = StandardScaler()\n",
    "    df[numerical_columns] = df[numerical_columns].replace([np.inf, -np.inf], np.nan)\n",
    "    df[numerical_columns] = df[numerical_columns].fillna(df[numerical_columns].mean())\n",
    "    df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "    return df, scaler\n",
    "\n",
    "df_test, _ = encode_categorical_columns(df_test, univ_categorical)\n",
    "df_test, _ = scale_numerical_columns(df_test, univ_numerical)\n",
    "\n",
    "df_test = pd.get_dummies(df_test, columns=['univ_state'], drop_first=True)\n",
    "\n",
    "for col in one_hot_columns:\n",
    "    if col not in df_test.columns:\n",
    "        df_test[col] = 0\n",
    "\n",
    "X_test = df_test[univ_categorical + univ_numerical + one_hot_columns]\n",
    "y_test = df_test['univName']\n",
    "\n",
    "\n",
    "# 5. EVALUATE THE HYBRID RECOMMENDER\n",
    "\n",
    "evaluate_hybrid_model(X_test, y_test, rf_model, cf_model, le_y_univ, one_hot_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9d571ee-e481-439e-a244-fff63d8279c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading existing models...\n",
      "‚úÖ Models loaded.\n",
      "üíæ Saving compressed versions...\n",
      "‚úÖ All models saved with compression at level 3.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "\n",
    "model_dir = \"models/university_models\"\n",
    "compressed_dir = \"models/university_models_compressed\"\n",
    "os.makedirs(compressed_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "print(\"üîÑ Loading existing models...\")\n",
    "rf_model_dict = joblib.load(os.path.join(model_dir, \"rf_university.pkl\"))\n",
    "cf_model = joblib.load(os.path.join(model_dir, \"cf_model_memory.pkl\"))\n",
    "scaler = joblib.load(os.path.join(model_dir, \"scaler_university.pkl\"))\n",
    "label_encoders = joblib.load(os.path.join(model_dir, \"label_encoders_university.pkl\"))\n",
    "le_y = joblib.load(os.path.join(model_dir, \"le_y_univ.pkl\"))\n",
    "one_hot_columns = joblib.load(os.path.join(model_dir, \"one_hot_columns_university.pkl\"))\n",
    "\n",
    "print(\"‚úÖ Models loaded.\")\n",
    "\n",
    "\n",
    "print(\"üíæ Saving compressed versions...\")\n",
    "\n",
    "joblib.dump(rf_model_dict, os.path.join(compressed_dir, \"rf_university.pkl\"), compress=9)\n",
    "joblib.dump(cf_model, os.path.join(compressed_dir, \"cf_model_memory.pkl\"), compress=9)\n",
    "joblib.dump(scaler, os.path.join(compressed_dir, \"scaler_university.pkl\"), compress=9)\n",
    "joblib.dump(label_encoders, os.path.join(compressed_dir, \"label_encoders_university.pkl\"), compress=9)\n",
    "joblib.dump(le_y, os.path.join(compressed_dir, \"le_y_univ.pkl\"), compress=9)\n",
    "joblib.dump(one_hot_columns, os.path.join(compressed_dir, \"one_hot_columns_university.pkl\"), compress=9)\n",
    "\n",
    "print(\"‚úÖ All models saved with compression at level 3.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a816ce72-cdd7-4676-9ad0-07eabf08124b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
