{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bde20b9f-c7ac-4c91-ab0d-0e00052e49e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Memory-Based Collaborative Filtering model trained.\n",
      "üìä Collaborative Filtering Evaluation Metrics:\n",
      "Precision: 0.7365\n",
      "Recall: 0.8207\n",
      "Accuracy: 0.9997\n",
      "F1 Score: 0.7763\n",
      "\n",
      "‚úÖ Collaborative Filtering model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "\n",
    "# 1. LOAD THE DATASET\n",
    "\n",
    "df = pd.read_csv('./data/categorized_specializations.csv')\n",
    "\n",
    "df.drop(columns=['program','ugCollege','univName_rank','acceptance_rate','univ_state'],axis=1, inplace=True)\n",
    "\n",
    "# Label encoding categorical columns\n",
    "def encode_categorical_columns(df, categorical_columns):\n",
    "    label_encoders = {}\n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = df[col].astype(str)\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "        label_encoders[col] = le\n",
    "    return df, label_encoders\n",
    "\n",
    "# Scaling continuous columns\n",
    "def scale_numerical_columns(df, numerical_columns):\n",
    "    scaler = StandardScaler()\n",
    "    df[numerical_columns] = df[numerical_columns].replace([np.inf, -np.inf], np.nan)\n",
    "    df[numerical_columns] = df[numerical_columns].fillna(df[numerical_columns].mean())\n",
    "    df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "    return df, scaler\n",
    "\n",
    "\n",
    "# 2. MEMORY-BASED COLLABORATIVE FILTERING CLASS\n",
    "\n",
    "from memory_cf import MemoryBasedCF\n",
    "\n",
    "\n",
    "# 3. TRAINING THE CF MODEL\n",
    "\n",
    "def train_collaborative_filtering_memory(df, user_col, item_col, rating_col):\n",
    "    \"\"\"\n",
    "    Trains a memory-based collaborative filtering model:\n",
    "      - Creates a pivot table for users and items.\n",
    "      - Normalizes ratings to be between 0 and 1.\n",
    "      - Computes cosine similarity.\n",
    "    Returns an instance of MemoryBasedCF.\n",
    "    \"\"\"\n",
    "    df[user_col] = df[user_col].astype(str)\n",
    "    df[item_col] = df[item_col].astype(str)\n",
    "    \n",
    "    # Normalize the rating column to a [0, 1] scale.\n",
    "    df[rating_col] = (df[rating_col] - df[rating_col].min()) / (df[rating_col].max() - df[rating_col].min())\n",
    "    \n",
    "    df_pivot = df.pivot_table(index=user_col, columns=item_col, values=rating_col, aggfunc='mean', fill_value=0)\n",
    "    cf_model = MemoryBasedCF(df_pivot)\n",
    "    print(\"‚úÖ Memory-Based Collaborative Filtering model trained.\")\n",
    "    return cf_model, df_pivot\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_cf_model_precision_recall_accuracy_f1(cf_model, df_pivot, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Evaluates the collaborative filtering model using Precision and Recall based on \n",
    "    predicted and actual ratings, considering ratings above a threshold as relevant.\n",
    "    \"\"\"\n",
    "    actual_relevance = []\n",
    "    predicted_relevance = []\n",
    "    \n",
    "    for user in df_pivot.index:\n",
    "        actual = df_pivot.loc[user].values\n",
    "        predicted = cf_model.predict(user)\n",
    "        \n",
    "        # Convert ratings to relevance (1 if relevant, 0 if not)\n",
    "        actual_relevance.extend((actual >= threshold).astype(int))\n",
    "        predicted_relevance.extend((predicted >= threshold).astype(int))\n",
    "    \n",
    "\n",
    "    # Compute Precision, Recall, Accuracy, and F1-Score\n",
    "    precision = precision_score(actual_relevance, predicted_relevance)\n",
    "    recall = recall_score(actual_relevance, predicted_relevance)\n",
    "    accuracy = accuracy_score(actual_relevance, predicted_relevance)\n",
    "    f1 = f1_score(actual_relevance, predicted_relevance)\n",
    "\n",
    "    print(f\"üìä Collaborative Filtering Evaluation Metrics:\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    return precision, recall, accuracy, f1\n",
    "\n",
    "\n",
    "\n",
    "cf_model, df_pivot = train_collaborative_filtering_memory(df, 'userName', 'specialization_category', 'admit')\n",
    "\n",
    "\n",
    "precision, recall, accuracy, f1 = evaluate_cf_model_precision_recall_accuracy_f1(cf_model, df_pivot)\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(cf_model, \"models/major_models/cf_model_spec.pkl\")\n",
    "\n",
    "print(\"\\n‚úÖ Collaborative Filtering model saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f884aebc-44ac-4a6a-840e-66de8ca80cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìå Sample User: User_9476\n",
      "\n",
      "Top Similar Users:\n",
      "Target User Similar User  Cosine Similarity\n",
      "  User_9476   User_13071           1.000000\n",
      "  User_9476    User_1673           0.816497\n",
      "  User_9476    User_7154           0.816497\n",
      "  User_9476    User_6208           0.707107\n",
      "  User_9476   User_13088           0.500000\n",
      "\n",
      "Top Specialization Recommendations:\n",
      "       Recommended Specialization  Predicted Score\n",
      "                   rf engineering         0.412027\n",
      "            microwave engineering         0.254098\n",
      "                   circuit design         0.077705\n",
      "                 electromagnetics         0.064983\n",
      "integrated circuit ic engineering         0.040760\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_top_similar_users(user_id, similarity_matrix, top_n=5):\n",
    "    similar_scores = similarity_matrix.loc[user_id].drop(user_id)  \n",
    "    top_similar = similar_scores.sort_values(ascending=False).head(top_n)\n",
    "    return top_similar\n",
    "\n",
    "def get_top_recommendations(user_id, cf_model, top_n=5):\n",
    "    predictions = cf_model.predict(user_id)\n",
    "    sorted_indices = np.argsort(predictions)[::-1]  \n",
    "    specialization_names = df_pivot.columns[sorted_indices][:top_n]\n",
    "    scores = predictions[sorted_indices][:top_n]\n",
    "    return list(zip(specialization_names, scores))\n",
    "\n",
    "def format_similar_users_table(user_id, similarity_matrix, user_id_map, top_n=5):\n",
    "    top_similar = get_top_similar_users(user_id, similarity_matrix, top_n)\n",
    "    return pd.DataFrame({\n",
    "        'Target User': user_id_map[user_id],\n",
    "        'Similar User': [user_id_map[u] for u in top_similar.index],\n",
    "        'Cosine Similarity': top_similar.values\n",
    "    })\n",
    "\n",
    "def format_top_recommendations_table(user_id, cf_model, top_n=5):\n",
    "    top_recs = get_top_recommendations(user_id, cf_model, top_n)\n",
    "    return pd.DataFrame(top_recs, columns=['Recommended Specialization', 'Predicted Score'])\n",
    "\n",
    "\n",
    "user_id = 'rishik.bazaz'\n",
    "\n",
    "user_id_map = {user: f\"User_{i}\" for i, user in enumerate(df_pivot.index)}\n",
    "\n",
    "# Compute similarity matrix for specialization CF\n",
    "similarity_matrix = pd.DataFrame(\n",
    "    cosine_similarity(df_pivot),\n",
    "    index=df_pivot.index,\n",
    "    columns=df_pivot.index\n",
    ")\n",
    "\n",
    "if user_id in df_pivot.index:\n",
    "    similar_users_df = format_similar_users_table(user_id, similarity_matrix, user_id_map)\n",
    "    recommendations_df = format_top_recommendations_table(user_id, cf_model)\n",
    "\n",
    "    print(f\"üìå Sample User: {user_id_map[user_id]}\\n\")\n",
    "    print(\"Top Similar Users:\")\n",
    "    print(similar_users_df.to_string(index=False))\n",
    "\n",
    "    print(\"\\nTop Specialization Recommendations:\")\n",
    "    print(recommendations_df.to_string(index=False))\n",
    "else:\n",
    "    print(f\"‚ùå User ID '{user_id}' not found in dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b6c25d2-6f7d-460b-b7ad-cf90e311f2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All specialization models and preprocessing objects loaded successfully.\n",
      "üìä Hybrid Specialization Model Evaluation:\n",
      "Accuracy: 0.8203\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94         8\n",
      "           1       0.83      1.00      0.91        10\n",
      "           2       0.73      0.51      0.60        43\n",
      "           3       0.33      0.50      0.40         2\n",
      "           4       0.80      1.00      0.89         4\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       0.81      1.00      0.90        13\n",
      "           7       0.36      1.00      0.53         4\n",
      "           8       0.94      0.57      0.71       118\n",
      "           9       0.43      0.75      0.55         4\n",
      "          10       0.33      1.00      0.50         1\n",
      "          11       1.00      0.80      0.89         5\n",
      "          12       0.76      0.81      0.79        16\n",
      "          13       0.57      0.92      0.71        13\n",
      "          14       1.00      0.80      0.89         5\n",
      "          15       1.00      1.00      1.00         2\n",
      "          16       1.00      1.00      1.00        14\n",
      "          17       1.00      1.00      1.00         4\n",
      "          18       1.00      1.00      1.00         2\n",
      "          19       0.71      1.00      0.83         5\n",
      "          20       0.67      0.50      0.57        20\n",
      "          21       1.00      1.00      1.00         2\n",
      "          22       1.00      1.00      1.00        15\n",
      "          23       0.83      1.00      0.91         5\n",
      "          24       0.67      1.00      0.80         2\n",
      "          25       1.00      0.89      0.94         9\n",
      "          26       0.71      0.83      0.77         6\n",
      "          27       0.67      0.90      0.77        31\n",
      "          28       1.00      1.00      1.00         6\n",
      "          29       1.00      1.00      1.00         5\n",
      "          30       0.71      1.00      0.83        17\n",
      "          31       1.00      1.00      1.00         3\n",
      "          32       1.00      1.00      1.00         4\n",
      "          33       1.00      1.00      1.00         4\n",
      "          34       0.67      1.00      0.80         2\n",
      "          35       0.50      1.00      0.67         2\n",
      "          36       1.00      0.67      0.80         6\n",
      "          37       1.00      1.00      1.00         1\n",
      "          38       0.89      1.00      0.94         8\n",
      "          39       0.68      0.62      0.65        79\n",
      "          40       1.00      1.00      1.00         5\n",
      "          41       0.87      0.96      0.91        93\n",
      "          42       0.75      0.53      0.62        17\n",
      "          43       1.00      1.00      1.00         3\n",
      "          44       0.94      0.68      0.79       107\n",
      "          45       0.98      0.98      0.98       843\n",
      "          46       1.00      1.00      1.00         1\n",
      "          47       0.50      0.67      0.57         3\n",
      "          48       0.44      1.00      0.62         4\n",
      "          49       0.77      0.59      0.67        39\n",
      "          50       0.50      1.00      0.67         3\n",
      "          51       1.00      1.00      1.00         2\n",
      "          52       1.00      0.94      0.97        16\n",
      "          53       1.00      1.00      1.00         2\n",
      "          54       0.71      0.71      0.71        28\n",
      "          55       1.00      1.00      1.00         4\n",
      "          56       0.33      0.50      0.40         2\n",
      "          57       0.17      1.00      0.29         1\n",
      "          58       0.76      0.82      0.78        38\n",
      "          59       0.50      1.00      0.67         1\n",
      "          60       0.50      0.83      0.62         6\n",
      "          61       0.43      1.00      0.60         3\n",
      "          62       0.78      0.54      0.64        72\n",
      "          63       1.00      1.00      1.00         1\n",
      "          64       0.65      0.81      0.72        16\n",
      "          65       0.00      0.00      0.00         0\n",
      "          66       0.72      0.87      0.79        15\n",
      "          67       0.62      0.81      0.70        32\n",
      "          68       0.60      1.00      0.75         3\n",
      "          69       0.44      0.67      0.53         6\n",
      "          70       1.00      0.60      0.75         5\n",
      "          71       0.61      0.56      0.58        45\n",
      "          72       1.00      1.00      1.00         6\n",
      "          73       0.74      0.72      0.73        32\n",
      "          74       0.71      0.60      0.65        25\n",
      "          75       0.67      1.00      0.80         4\n",
      "          76       0.67      0.94      0.78        32\n",
      "          77       0.62      0.59      0.61        17\n",
      "          78       0.45      0.78      0.57        27\n",
      "          79       0.50      1.00      0.67         3\n",
      "          80       0.50      1.00      0.67         1\n",
      "          81       1.00      1.00      1.00         3\n",
      "          82       0.90      0.90      0.90        10\n",
      "          83       1.00      1.00      1.00         1\n",
      "          84       1.00      1.00      1.00         1\n",
      "          85       0.99      0.96      0.97        71\n",
      "          86       0.67      0.67      0.67         3\n",
      "          87       0.97      0.97      0.97        38\n",
      "          88       0.83      1.00      0.91         5\n",
      "          89       0.87      0.65      0.74       211\n",
      "          90       0.50      0.67      0.57        15\n",
      "          91       0.78      1.00      0.88         7\n",
      "          92       1.00      0.86      0.92        21\n",
      "          93       0.60      1.00      0.75         3\n",
      "          94       1.00      0.91      0.95        11\n",
      "          95       0.67      1.00      0.80         2\n",
      "          96       1.00      1.00      1.00         2\n",
      "          97       0.70      1.00      0.82         7\n",
      "          98       0.40      0.67      0.50         3\n",
      "          99       0.00      0.00      0.00         0\n",
      "         100       0.70      0.74      0.72        19\n",
      "         101       1.00      0.75      0.86         4\n",
      "         102       1.00      1.00      1.00         5\n",
      "         103       0.71      0.83      0.77        12\n",
      "         104       1.00      1.00      1.00         1\n",
      "         105       0.56      0.90      0.69        10\n",
      "         106       1.00      1.00      1.00         9\n",
      "         107       0.63      0.92      0.75        13\n",
      "         108       0.42      0.83      0.56        12\n",
      "         109       0.57      0.89      0.70        18\n",
      "         110       1.00      0.99      0.99        67\n",
      "         111       0.40      1.00      0.57         2\n",
      "         112       1.00      1.00      1.00         1\n",
      "         113       0.36      0.92      0.52        13\n",
      "         114       1.00      1.00      1.00         1\n",
      "         115       0.88      0.86      0.87        49\n",
      "         116       0.95      0.95      0.95        21\n",
      "         117       0.62      1.00      0.77         5\n",
      "         118       0.91      0.87      0.89        23\n",
      "         119       1.00      1.00      1.00         1\n",
      "         120       0.43      1.00      0.60         3\n",
      "         121       0.80      1.00      0.89         4\n",
      "         122       0.81      0.63      0.71        75\n",
      "         123       0.50      1.00      0.67         1\n",
      "         124       0.92      0.96      0.94        23\n",
      "         125       0.84      0.76      0.80        21\n",
      "         126       0.62      0.83      0.71         6\n",
      "         127       1.00      1.00      1.00         7\n",
      "         128       0.98      0.88      0.92        49\n",
      "         129       0.50      0.75      0.60         4\n",
      "         130       0.45      1.00      0.62         5\n",
      "         131       0.67      1.00      0.80         4\n",
      "         132       0.20      0.50      0.29         2\n",
      "         133       0.75      0.75      0.75         4\n",
      "         134       0.65      1.00      0.79        11\n",
      "         135       0.60      0.75      0.67         4\n",
      "         136       0.99      0.99      0.99       324\n",
      "         137       0.60      1.00      0.75         3\n",
      "         138       0.00      0.00      0.00         2\n",
      "         139       1.00      1.00      1.00         1\n",
      "         140       1.00      0.40      0.57         5\n",
      "         141       0.88      0.78      0.82         9\n",
      "         142       0.41      0.70      0.52        10\n",
      "         143       0.25      1.00      0.40         3\n",
      "         144       0.50      1.00      0.67         3\n",
      "         145       0.90      0.86      0.88        21\n",
      "         146       0.99      0.57      0.72       116\n",
      "         147       0.84      0.65      0.73        88\n",
      "         148       1.00      1.00      1.00         2\n",
      "         149       0.91      0.89      0.90        56\n",
      "         150       0.34      0.43      0.38        23\n",
      "         151       1.00      1.00      1.00         2\n",
      "         152       0.81      0.63      0.71        27\n",
      "         153       1.00      1.00      1.00         3\n",
      "         154       0.00      0.00      0.00         0\n",
      "         155       1.00      1.00      1.00         4\n",
      "         156       0.24      0.80      0.36         5\n",
      "         157       0.67      1.00      0.80         2\n",
      "         158       1.00      1.00      1.00         2\n",
      "         159       0.27      1.00      0.43         3\n",
      "         160       1.00      1.00      1.00         3\n",
      "         161       0.67      0.83      0.74        12\n",
      "         162       1.00      1.00      1.00         2\n",
      "         163       0.67      0.86      0.75         7\n",
      "         164       0.92      0.79      0.85        42\n",
      "         165       1.00      0.67      0.80         3\n",
      "         166       0.25      1.00      0.40         1\n",
      "         167       0.89      0.73      0.80        11\n",
      "         168       0.53      1.00      0.69        18\n",
      "         169       0.50      1.00      0.67         3\n",
      "         170       1.00      1.00      1.00         4\n",
      "         171       0.25      1.00      0.40         1\n",
      "         172       1.00      0.50      0.67         2\n",
      "         173       0.00      0.00      0.00         0\n",
      "         174       0.57      0.57      0.57         7\n",
      "         175       0.67      0.62      0.65        32\n",
      "         176       0.50      1.00      0.67         1\n",
      "         177       0.45      1.00      0.62         5\n",
      "         178       0.91      0.81      0.86        52\n",
      "         179       1.00      1.00      1.00        10\n",
      "         180       1.00      1.00      1.00         2\n",
      "         181       1.00      1.00      1.00         2\n",
      "         182       0.87      0.68      0.76        59\n",
      "         183       0.50      1.00      0.67         4\n",
      "         184       0.20      0.50      0.29         2\n",
      "         185       0.33      0.25      0.29         4\n",
      "         186       0.94      1.00      0.97        31\n",
      "         187       0.73      0.73      0.73        30\n",
      "         188       0.73      0.69      0.71        75\n",
      "         189       1.00      1.00      1.00         2\n",
      "         190       0.75      1.00      0.86         3\n",
      "         191       0.93      1.00      0.97        14\n",
      "         192       0.29      1.00      0.44         2\n",
      "         193       1.00      1.00      1.00         2\n",
      "         194       0.60      0.83      0.70        35\n",
      "         195       0.45      0.83      0.59         6\n",
      "         196       0.80      0.80      0.80        10\n",
      "         197       1.00      1.00      1.00         4\n",
      "         198       0.65      0.65      0.65        17\n",
      "         199       0.50      1.00      0.67         2\n",
      "         200       1.00      1.00      1.00         1\n",
      "         201       0.80      1.00      0.89         4\n",
      "         202       0.70      1.00      0.82         7\n",
      "         203       1.00      1.00      1.00         3\n",
      "         204       1.00      1.00      1.00         1\n",
      "         205       1.00      1.00      1.00         3\n",
      "         206       0.83      0.83      0.83         6\n",
      "         207       1.00      1.00      1.00         1\n",
      "         208       0.84      0.66      0.74       169\n",
      "         209       0.00      0.00      0.00         0\n",
      "         210       0.25      1.00      0.40         1\n",
      "         211       0.78      0.65      0.70        48\n",
      "         212       0.75      1.00      0.86         3\n",
      "         213       1.00      0.83      0.91         6\n",
      "         214       0.74      0.93      0.82        15\n",
      "         215       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.82      4491\n",
      "   macro avg       0.73      0.85      0.76      4491\n",
      "weighted avg       0.85      0.82      0.83      4491\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Keerthana\\anaconda3.12\\envs\\FYP\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Keerthana\\anaconda3.12\\envs\\FYP\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\Keerthana\\anaconda3.12\\envs\\FYP\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# 1. LOAD SAVED MODELS & PREPROCESSING OBJECTS\n",
    "\n",
    "spec_save_dir = \"models/major_models\"\n",
    "\n",
    "# Load content-based models:\n",
    "rf_model = joblib.load(os.path.join(spec_save_dir, \"rf_specialization.pkl\"))[0]\n",
    "\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.load_model(os.path.join(spec_save_dir, \"xgb_specialization.json\"))\n",
    "\n",
    "cf_model = joblib.load(os.path.join(spec_save_dir, \"cf_model_spec.pkl\"))\n",
    "\n",
    "label_encoders_spec = joblib.load(os.path.join(spec_save_dir, \"label_encoders_specialization.pkl\"))\n",
    "scaler_spec = joblib.load(os.path.join(spec_save_dir, \"scaler_specialization.pkl\"))\n",
    "le_y_spec = joblib.load(os.path.join(spec_save_dir, \"le_y_spec.pkl\"))\n",
    "\n",
    "print(\"‚úÖ All specialization models and preprocessing objects loaded successfully.\")\n",
    "\n",
    "\n",
    "# 2. Load the test dataset\n",
    "df_test = pd.read_csv('./data/categorized_specializations.csv')\n",
    "df_test = df_test.sample(n=5000, random_state=42)  \n",
    "\n",
    "df_test.drop(columns=['program', 'ugCollege', 'univName_rank', 'acceptance_rate', 'univ_state'], axis=1, inplace=True)\n",
    "\n",
    "spec_categorical = ['major']\n",
    "spec_numerical   = ['researchExp', 'industryExp', 'toeflScore', 'internExp', 'greV', 'greQ', 'greA', 'normalized_cgpa']\n",
    "\n",
    "\n",
    "for col in spec_categorical:\n",
    "    le = label_encoders_spec[col]\n",
    "    df_test[col] = df_test[col].astype(str)\n",
    "    df_test[col] = le.transform(df_test[col])\n",
    "\n",
    "\n",
    "df_test[spec_numerical] = df_test[spec_numerical].replace([np.inf, -np.inf], np.nan)\n",
    "df_test[spec_numerical] = df_test[spec_numerical].fillna(df_test[spec_numerical].mean())\n",
    "df_test[spec_numerical] = scaler_spec.transform(df_test[spec_numerical])\n",
    "\n",
    "\n",
    "known_labels = set(le_y_spec.classes_)\n",
    "df_test = df_test[df_test['specialization_category'].isin(known_labels)]\n",
    "\n",
    "\n",
    "X_test = df_test[spec_categorical + spec_numerical]\n",
    "y_test = df_test['specialization_category']\n",
    "\n",
    "\n",
    "\n",
    "# 3. DEFINE HYBRID SPECIALIZATION RECOMMENDATION FUNCTION\n",
    "\n",
    "def hybrid_specialization_recommendation(input_df, rf_model, xgb_model, cf_model, le_y):\n",
    "    input_features = input_df.drop(columns=['userName'], errors='ignore')\n",
    "\n",
    "    rf_probs = rf_model.predict_proba(input_features)[0]\n",
    "    xgb_probs = xgb_model.predict_proba(input_features)[0]\n",
    "    content_probs = (rf_probs + xgb_probs) / 2\n",
    "\n",
    "    collab_probs = np.zeros_like(content_probs)\n",
    "\n",
    "    if 'userName' in input_df.columns:\n",
    "        input_user = input_df.iloc[0]['userName']\n",
    "        cf_raw_probs = cf_model.predict(input_user)\n",
    "\n",
    "        # Align CF output with label encoder classes\n",
    "        cf_items = cf_model.item_ids\n",
    "        cf_prob_dict = dict(zip(cf_items, cf_raw_probs))\n",
    "\n",
    "        aligned_cf_probs = []\n",
    "        for class_label in le_y.classes_:\n",
    "            aligned_cf_probs.append(cf_prob_dict.get(class_label, 0.0))\n",
    "\n",
    "        collab_probs = np.array(aligned_cf_probs)\n",
    "\n",
    "    # Combine with variance-based weighting\n",
    "    alpha = np.var(content_probs) / (np.var(content_probs) + np.var(collab_probs) + 1e-5)\n",
    "    final_probs = (content_probs * alpha) + (collab_probs * (1 - alpha))\n",
    "\n",
    "    top_n = 5\n",
    "    top_indices = np.argsort(final_probs)[-top_n:][::-1]\n",
    "    recommendations = le_y.inverse_transform(top_indices)\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "# 4. EVALUATE THE HYBRID MODEL\n",
    "\n",
    "def evaluate_hybrid_specialization(X_test, y_test, rf_model, xgb_model, cf_model, le_y):\n",
    "    \"\"\"\n",
    "    Evaluates the hybrid specialization recommender by:\n",
    "      - Generating recommendations for each test sample.\n",
    "      - Taking the top recommendation as the predicted specialization.\n",
    "      - Comparing against the true specialization label.\n",
    "    Prints the overall accuracy and a detailed classification report.\n",
    "    \"\"\"\n",
    "    y_test_encoded = le_y.transform(y_test)\n",
    "    y_pred = []\n",
    "    \n",
    "    for i in range(len(X_test)):\n",
    "        sample = X_test.iloc[[i]].copy()\n",
    "\n",
    "        if 'userName' not in sample.columns:\n",
    "            sample['userName'] = \"dummy_user\"\n",
    "        \n",
    "        recs = hybrid_specialization_recommendation(sample, rf_model, xgb_model, cf_model, le_y)\n",
    "\n",
    "        if len(recs) > 0:\n",
    "            pred = le_y.transform([recs[0]])[0]\n",
    "        else:\n",
    "            pred = -1  \n",
    "        y_pred.append(pred)\n",
    "    \n",
    "\n",
    "    valid_idx = [i for i, p in enumerate(y_pred) if p != -1]\n",
    "    y_true_valid = np.array([y_test_encoded[i] for i in valid_idx])\n",
    "    y_pred_valid = np.array([y_pred[i] for i in valid_idx])\n",
    "    \n",
    "    acc = accuracy_score(y_true_valid, y_pred_valid)\n",
    "    print(\"üìä Hybrid Specialization Model Evaluation:\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(classification_report(y_true_valid, y_pred_valid))\n",
    "    \n",
    "# Run the evaluation:\n",
    "evaluate_hybrid_specialization(X_test, y_test, rf_model, xgb_model, cf_model, le_y_spec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d724d572-f1aa-48d7-b54a-156ee04ff4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading specialization models...\n",
      "‚úÖ Models loaded.\n",
      "üíæ Saving compressed model files...\n",
      "üìÅ Copying xgb_specialization.json to compressed directory...\n",
      "‚úÖ All specialization models saved and copied to 'major_models_compressed'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import shutil\n",
    "\n",
    "\n",
    "from memory_cf import MemoryBasedCF\n",
    "\n",
    "\n",
    "source_dir = \"models/major_models\"\n",
    "compressed_dir = \"models/major_models_compressed\"\n",
    "os.makedirs(compressed_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "print(\"üîÑ Loading specialization models...\")\n",
    "\n",
    "rf_model = joblib.load(os.path.join(source_dir, \"rf_specialization.pkl\"))\n",
    "cf_model = joblib.load(os.path.join(source_dir, \"cf_model_spec.pkl\"))\n",
    "scaler = joblib.load(os.path.join(source_dir, \"scaler_specialization.pkl\"))\n",
    "label_encoders = joblib.load(os.path.join(source_dir, \"label_encoders_specialization.pkl\"))\n",
    "le_y = joblib.load(os.path.join(source_dir, \"le_y_spec.pkl\"))\n",
    "\n",
    "print(\"‚úÖ Models loaded.\")\n",
    "\n",
    "\n",
    "print(\"üíæ Saving compressed model files...\")\n",
    "\n",
    "joblib.dump(rf_model, os.path.join(compressed_dir, \"rf_specialization.pkl\"), compress=3)\n",
    "joblib.dump(cf_model, os.path.join(compressed_dir, \"cf_model_spec.pkl\"), compress=3)\n",
    "joblib.dump(scaler, os.path.join(compressed_dir, \"scaler_specialization.pkl\"), compress=3)\n",
    "joblib.dump(label_encoders, os.path.join(compressed_dir, \"label_encoders_specialization.pkl\"), compress=3)\n",
    "joblib.dump(le_y, os.path.join(compressed_dir, \"le_y_spec.pkl\"), compress=3)\n",
    "\n",
    "\n",
    "print(\"üìÅ Copying xgb_specialization.json to compressed directory...\")\n",
    "shutil.copyfile(\n",
    "    os.path.join(source_dir, \"xgb_specialization.json\"),\n",
    "    os.path.join(compressed_dir, \"xgb_specialization.json\")\n",
    ")\n",
    "\n",
    "print(\"‚úÖ All specialization models saved and copied to 'major_models_compressed'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beffee5-1d80-42d5-80b9-637cfd17e8c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
